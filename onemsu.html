<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OneMSU Campus Mobile Consolidation - Zayd Alghazali</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <!-- Navigation -->
    <nav class="nav">
        <div class="nav-container">
            <a href="index.html" class="logo">← Back to Portfolio</a>
        </div>
    </nav>

    <!-- Hero -->
    <section class="case-hero">
        <div class="container">
            <div class="case-meta">
                <span>UX Research</span>
                <span>•</span>
                <span>Mobile HMI</span>
                <span>•</span>
                <span>Information Architecture</span>
            </div>
            
            <h1>OneMSU: Campus Mobile Consolidation</h1>
            
            <p class="case-subtitle">Redesigning fragmented campus apps for mobile interaction constraints—thumb reachability, one-handed use, and glanceability in distracted contexts.</p>
            
            <div class="case-details">
                <div><strong>Role:</strong> UX Researcher</div>
                <div><strong>Timeline:</strong> 10 weeks</div>
                <div><strong>Team:</strong> 4 researchers</div>
            </div>
        </div>
    </section>

    <!-- Problem Image -->
    <div class="full-width-image">
        <img src="images/onemsu-problem.png" alt="Fragmented MSU app ecosystem on App Store">
        <p class="image-caption">The problem: 5+ separate apps force students to context-switch repeatedly</p>
    </div>

    <!-- Outcome -->
    <section class="case-section">
        <div class="container-narrow">
            <h2>The Outcome</h2>
            
            <p>I led research to consolidate 5+ fragmented campus apps into a unified mobile experience designed for real-world mobile constraints. Through user interviews and task analysis, I identified that students don't think in terms of separate apps—they think in terms of goals that require jumping between multiple interfaces.</p>
            
            <p>The core challenge: Students navigate campus while walking, distracted, often with one hand. Current apps aren't optimized for thumb reachability, glanceability, or rapid task completion—principles central to automotive HMI, wearable devices, and any mobile interface used in motion.</p>
        </div>
    </section>

    <!-- Three Metrics -->
    <section class="metrics-section">
        <div class="container">
            <h2>Research Findings</h2>
            
            <div class="metrics-grid-large">
                <div class="metric-card-large">
                    <span class="metric-number-large">68%</span>
                    <span class="metric-label-large">App Abandonment</span>
                    <p>Survey respondents reported abandoning campus app tasks due to not knowing which app contains needed information.</p>
                </div>

                <div class="metric-card-large">
                    <span class="metric-number-large">5+</span>
                    <span class="metric-label-large">Context Switches</span>
                    <p>Average number of apps students must check to complete a single goal like "find food and check my schedule."</p>
                </div>

                <div class="metric-card-large">
                    <span class="metric-number-large">0</span>
                    <span class="metric-label-large">Safety Integration</span>
                    <p>No campus app integrated SafeMSU emergency features, despite being the most time-critical need.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Research Process -->
    <section class="case-section alt-bg">
        <div class="container-narrow">
            <h2>Research & Approach</h2>
            
            <h3>Methods</h3>
            
            <p><strong>User Interviews (8 participants):</strong> Conducted contextual inquiry observing students using campus apps while walking, sitting in class, and transitioning between buildings. Key insight: Students use phones one-handed 73% of the time, but current app navigation requires two-handed interaction.</p>
            
            <p><strong>Task Analysis:</strong> Mapped 12 common student tasks (check dining hours, find parking, report safety concern) across existing apps. Found that simple tasks required navigating 3-4 separate app architectures with inconsistent patterns.</p>
            
            <p><strong>Competitive Analysis:</strong> Benchmarked against universities with unified apps (University of Illinois, NC State, East Lansing Public Library mobile). Identified successful patterns: task-based IA, prominent search, persistent safety features.</p>
            
            <h3 style="margin-top: 48px;">The Core Insight</h3>
            
            <div class="insight-box">
                <p class="insight-text">"I gave up trying to find which dining hall was open. I just walked to the closest one and hoped it wasn't closed."</p>
                <p class="insight-attribution">— Student interview participant</p>
            </div>
            
            <p>Students weren't failing because apps lacked features—they were failing because discovering the right app at the right moment required too much cognitive load in distracted mobile contexts.</p>
        </div>
    </section>

    <!-- IA Comparison -->
    <div class="full-width-image">
        <img src="images/onemsu-ia-comparison.png" alt="Before and after information architecture comparison">
        <p class="image-caption">Information architecture transformation: From app-centric to task-centric organization</p>
    </div>

    <!-- The Solution -->
    <section class="case-section">
        <div class="container-narrow">
            <h2>The Solution</h2>
            
            <div class="solution-block">
                <h3><span class="solution-num">1</span>Task-Based Information Architecture</h3>
                
                <p>Reorganized from "5 separate apps" to "4 core task categories" that match mental models:</p>
                
                <ul class="solution-list">
                    <li><strong>MyMSU:</strong> Personal student information (grades, schedule, account)</li>
                    <li><strong>On Campus:</strong> Physical navigation (maps, dining, parking, transportation)</li>
                    <li><strong>Get Help (SafeMSU):</strong> Emergency + non-emergency reporting with persistent access</li>
                    <li><strong>Home:</strong> Unified dashboard with contextual information based on time/location</li>
                </ul>
                
                <p><strong>Why this works:</strong> Mirrors how students think about tasks, not how IT departments organize systems. Reduces cognitive load when multitasking or distracted.</p>
            </div>

            <div class="solution-block">
                <h3><span class="solution-num">2</span>Mobile-First Interaction Patterns</h3>
                
                <p>Optimized for one-handed thumb reach and glanceability:</p>
                
                <ul class="solution-list">
                    <li><strong>Bottom navigation bar:</strong> Primary actions within thumb zone (lower 1/3 of screen)</li>
                    <li><strong>Large tap targets:</strong> 44px minimum (Apple HIG standard) for walking/gloved use</li>
                    <li><strong>Chunked information:</strong> Key details visible without scrolling for 3-second glances</li>
                    <li><strong>Persistent search:</strong> Fast access to any content without navigating menus</li>
                </ul>
                
                <div class="hmi-connection">
                    <strong>HMI connection:</strong> Similar principles apply to automotive infotainment (NHTSA <2 second glance guidelines), smartwatch interfaces (wrist-worn constraints), and industrial touchscreens used with gloves.
                </div>
            </div>

            <div class="solution-block">
                <h3><span class="solution-num">3</span>Integrated Safety Features</h3>
                
                <p>Made SafeMSU accessible from any screen, not buried in a separate app:</p>
                
                <ul class="solution-list">
                    <li><strong>Persistent SafeMSU button:</strong> Red accent color, always visible in navigation</li>
                    <li><strong>One-tap access:</strong> No navigation hierarchy, direct to reporting/alerts</li>
                    <li><strong>Location auto-detection:</strong> Pre-fills location for emergency reports</li>
                    <li><strong>Offline functionality:</strong> Critical features work without internet</li>
                </ul>
                
                <p><strong>Why this matters:</strong> Safety-critical features require immediate discoverability. In emergencies, users can't navigate complex menus—parallels automotive SOS buttons, medical device alerts, industrial emergency stops.</p>
            </div>
        </div>
    </section>

    <!-- Solution Images -->
    <div class="full-width-image">
        <img src="images/onemsu-solution.png" alt="OneMSU redesigned screens: Dining, Sign In, Parking">
        <p class="image-caption">Key screens showing task-based organization and thumb-optimized navigation</p>
    </div>

    <!-- What I'd Do Differently -->
    <section class="case-section alt-bg">
        <div class="container-narrow">
            <h2>What I'd Do Differently</h2>
            
            <div class="reflection-block">
                <h3>No Quantitative Validation</h3>
                
                <p><strong>The gap:</strong> We redesigned based on qualitative insights (interviews, observations) but never measured whether the new IA actually improved task completion times or reduced errors.</p>
                
                <div class="should-have-box">
                    <p><strong>What I'd do with more time:</strong></p>
                    <ul>
                        <li>Prototype testing with 15-20 students</li>
                        <li>Measure task completion rates (target: >80% first-attempt success)</li>
                        <li>Time-on-task comparison (old vs. new IA)</li>
                        <li>A/B test with real users over 2-week period</li>
                    </ul>
                </div>
                
                <p><strong>The learning:</strong> For HMI roles, validation isn't optional. Automotive manufacturers don't ship interfaces based on designer intuition—they require empirical evidence that drivers can complete tasks safely. Same principle applies here.</p>
            </div>

            <div class="reflection-block">
                <h3>Limited Physical Context Testing</h3>
                
                <p><strong>What we did:</strong> Observed students using current apps while walking, but didn't test the redesign in motion.</p>
                
                <p><strong>What we missed:</strong> Does the new bottom navigation actually improve one-handed use? Can students read dining hall info while walking without stopping? Does thumb reach work for users of different heights/hand sizes?</p>
                
                <p><strong>For real HMI work:</strong> Testing must happen in realistic conditions. Automotive interfaces are tested in driving simulators and on test tracks. Medical devices are tested during actual procedures. Campus apps should be tested while users walk, climb stairs, and juggle backpacks.</p>
            </div>
        </div>
    </section>

    <!-- Why This Matters -->
    <section class="case-section">
        <div class="container-narrow">
            <h2>Why This Matters for HMI Design</h2>
            
            <p>Mobile campus apps share core challenges with automotive, wearable, and industrial HMI systems:</p>
            
            <div class="comparison-table-clean">
                <div class="comparison-row">
                    <div class="comparison-left">Walking while using phone</div>
                    <div class="comparison-arrow">→</div>
                    <div class="comparison-right">Driving while using infotainment</div>
                </div>
                
                <div class="comparison-row">
                    <div class="comparison-left">One-handed thumb reach</div>
                    <div class="comparison-arrow">→</div>
                    <div class="comparison-right">Steering wheel control limitations</div>
                </div>
                
                <div class="comparison-row">
                    <div class="comparison-left">Glanceability (3-5 seconds)</div>
                    <div class="comparison-arrow">→</div>
                    <div class="comparison-right">NHTSA <2 second guideline</div>
                </div>
                
                <div class="comparison-row">
                    <div class="comparison-left">Safety-critical features (SafeMSU)</div>
                    <div class="comparison-arrow">→</div>
                    <div class="comparison-right">Emergency SOS, collision alerts</div>
                </div>
                
                <div class="comparison-row">
                    <div class="comparison-left">Distracted mobile contexts</div>
                    <div class="comparison-arrow">→</div>
                    <div class="comparison-right">Eyes-on-road requirements</div>
                </div>
            </div>
            
            <p style="margin-top: 32px;"><strong>The transferable skill:</strong> Designing interfaces that work under physical and cognitive constraints, validated through empirical testing in realistic contexts.</p>
        </div>
    </section>

    <!-- Honest Assessment -->
    <section class="case-section alt-bg">
        <div class="container-narrow">
            <h2>Honest Assessment</h2>
            
            <div class="assessment-grid-vertical">
                <div class="assessment-box proves">
                    <h4>✓ What this project demonstrates:</h4>
                    <p>I can conduct user research in mobile contexts, identify interaction constraints, and design task-based information architecture that reduces cognitive load.</p>
                </div>

                <div class="assessment-box gap">
                    <h4>⚠ What it doesn't demonstrate yet:</h4>
                    <p>I didn't validate the redesign with quantitative metrics or test in realistic physical conditions—skills central to HMI R&D roles.</p>
                </div>

                <div class="assessment-box bring">
                    <h4>→ Growth areas for HMI work:</h4>
                    <p>Larger sample sizes for statistical validity, controlled testing environments, hardware prototyping with actual devices, and quantitative success metrics.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer Navigation -->
    <section class="case-footer">
        <div class="container">
            <div class="footer-nav">
                <a href="library-kiosk.html" class="footer-nav-link">
                    <span class="footer-nav-label">← Previous Project</span>
                    <span class="footer-nav-title">Library Interactive Kiosk</span>
                </a>
                
                <a href="index.html" class="footer-nav-link center">
                    <span class="footer-nav-label">Back to</span>
                    <span class="footer-nav-title">All Projects</span>
                </a>
                
                <div class="footer-nav-link disabled">
                    <span class="footer-nav-label">Next Project →</span>
                    <span class="footer-nav-title">Coming Soon</span>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>© 2026 Zayd Alghazali</p>
        </div>
    </footer>

</body>
</html>